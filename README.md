# MLOps Taller 3 - Pipeline Automatizado con Airflow

**Grupo compuesto por Sebastian Rodr√≠guez y David C√≥rdova**

Este proyecto implementa un pipeline completo de Machine Learning Operations (MLOps) que automatiza desde la limpieza de datos hasta el entrenamiento de modelos y despliegue de API, utilizando Apache Airflow como orquestador principal.

## Caracter√≠sticas Principales

- Pipeline completamente automatizado - Ejecuci√≥n autom√°tica sin intervenci√≥n manual
- Orquestaci√≥n con Apache Airflow - Gesti√≥n inteligente del flujo de trabajo
- Contenerizaci√≥n completa - Docker Compose para todos los servicios
- Base de datos MySQL - Almacenamiento persistente de datos
- API FastAPI - Servicio de predicciones en tiempo real
- Auto-trigger del DAG - Activaci√≥n autom√°tica al iniciar el sistema
- Monitoreo en tiempo real - Dashboard web de Airflow

## Estructura del Proyecto

```
MLOps_Taller3/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ funciones.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queries.py
‚îÇ   ‚îú‚îÄ‚îÄ fastapi_ready.txt
‚îÇ   ‚îú‚îÄ‚îÄ fastapi.log
‚îÇ   ‚îî‚îÄ‚îÄ orquestador.py
‚îú‚îÄ‚îÄ fastapi/
‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ logs/
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ plugins/
‚îú‚îÄ‚îÄ images/
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îî‚îÄ‚îÄ README.md
```

### Descripci√≥n de Componentes

- **dags/**:
  - **orquestador.py**: DAG principal de Airflow que automatiza todo el pipeline de Machine Learning.
  - **scripts/funciones.py**: Funciones principales del pipeline (insert_data, read_data, train_model).
  - **scripts/queries.py**: Consultas SQL para creaci√≥n y manipulaci√≥n de tablas en MySQL.
  - **fastapi_ready.txt**: Archivo de se√±al para indicar que FastAPI est√° listo.
  - **fastapi.log**: Logs del servicio FastAPI.

- **fastapi/**:
  - **main.py**: Aplicaci√≥n principal de FastAPI que consume los modelos entrenados.
  - **Dockerfile**: Contenerizaci√≥n del servicio API.
  - **requirements.txt**: Dependencias espec√≠ficas para el servicio FastAPI.

- **logs/**:
  - Directorio donde Airflow almacena todos los logs de ejecuci√≥n de tareas y DAGs.

- **models/**:
  - Carpeta compartida que almacena los modelos entrenados en formato pickle (.pkl).
  - Es montada como volumen en todos los contenedores que necesitan acceso a los modelos.
  - Contiene archivos como: `RegresionLogistica.pkl`.

- **plugins/**:
  - Directorio para plugins personalizados de Airflow (vac√≠o por defecto).

- **images/**:
  - Carpeta para almacenar capturas de pantalla y evidencias del funcionamiento del sistema.

- **.env**:
  - Archivo de variables de entorno que configura autom√°ticamente las credenciales de Airflow.
  - Elimina la necesidad de configuraci√≥n manual con credenciales predeterminadas (admin/admin).

- **docker-compose.yaml**:
  - Archivo de orquestaci√≥n que define y gestiona todos los contenedores del proyecto.
  - Incluye servicios para: Airflow (webserver, scheduler, worker, triggerer), MySQL, Redis, PostgreSQL, FastAPI.
  - Contiene el servicio `dag-auto-trigger` que ejecuta autom√°ticamente el pipeline despu√©s del inicio.
  - Facilita el montaje de vol√∫menes para compartir modelos y datos entre contenedores.
  - Configura la red interna para comunicaci√≥n entre servicios.

---

## Automatizaci√≥n Implementada

### Por qu√© se automatiz√≥

**Problema original:**
- Requer√≠a login manual en Airflow (`admin`/`admin`)
- Necesitaba activar DAGs manualmente
- Requer√≠a trigger manual del pipeline
- Intervenci√≥n humana en m√∫ltiples pasos

**Soluci√≥n automatizada:**
- Zero-touch deployment - Una sola ejecuci√≥n automatiza todo
- Auto-activaci√≥n de DAGs - Se activan autom√°ticamente al iniciar
- Auto-trigger del pipeline - Se ejecuta autom√°ticamente una vez
- Credenciales simplificadas - Admin/admin predeterminado

### Componentes de Automatizaci√≥n

#### Archivo .env - Configuraci√≥n Autom√°tica

```bash
# Variables de entorno para automatizaci√≥n
AIRFLOW_UID=50000
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=admin
AIRFLOW_PROJ_DIR=.
```

**Funci√≥n:** Elimina la necesidad de configuraci√≥n manual de credenciales.

#### docker-compose.yaml - Orquestaci√≥n Autom√°tica

**Caracter√≠sticas de automatizaci√≥n implementadas:**

```yaml
# DAGs activos por defecto (sin intervenci√≥n manual)
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'

# Detecci√≥n r√°pida de cambios en DAGs
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30
AIRFLOW__SCHEDULER__PARSING_PROCESSES: 2
```

**Servicio de Auto-Trigger integrado:**
```yaml
dag-auto-trigger:
  command: >
    bash -c "
      echo 'Iniciando auto-trigger del DAG...'
      sleep 120
      echo 'Activando DAG orquestador...'
      airflow dags unpause orquestador || echo 'DAG ya est√° activo'
      echo 'Disparando ejecuci√≥n del DAG...'
      airflow dags trigger orquestador
      echo 'DAG disparado exitosamente!'
    "
```

**Funci√≥n:** Ejecuta autom√°ticamente el pipeline 2 minutos despu√©s del inicio completo.

#### DAG Modificado - orquestador.py

**Configuraci√≥n para auto-activaci√≥n:**
```python
with DAG(
    dag_id="orquestador",
    schedule_interval=None,          # Ejecuci√≥n controlada autom√°ticamente
    catchup=False,
    is_paused_upon_creation=False,   # CLAVE: DAG activo desde creaci√≥n
    tags=['ml', 'penguins', 'auto-execution']
) as dag:
```

**Funci√≥n:** Garantiza que el DAG est√© listo para ejecuci√≥n autom√°tica.

## Flujo del Pipeline Automatizado

### Secuencia de Ejecuci√≥n Autom√°tica:

1. docker-compose up
2. Servicios iniciando (MySQL + Redis + PostgreSQL)
3. Airflow Webserver + Scheduler
4. DAG auto-activo
5. Auto-trigger despu√©s de 120 segundos
6. Pipeline ML ejecut√°ndose autom√°ticamente

### Tareas del DAG:

1. **delete_table** - Limpia tabla anterior de datos raw
2. **delete_table_clean** - Limpia tabla anterior de datos procesados  
3. **create_table_raw** - Crea tabla para datos originales
4. **create_table_clean** - Crea tabla para datos limpios
5. **insert_penguins** - Carga dataset Palmer Penguins a MySQL
6. **read_data** - Lee y procesa datos desde MySQL
7. **train_model** - Entrena modelo de Regresi√≥n Log√≠stica
8. **wait_for_model_file** - Verifica que modelo est√© guardado
9. **pipeline_completion** - Confirma finalizaci√≥n exitosa

## Instrucciones de Ejecuci√≥n

### Preparaci√≥n Inicial

```bash
# Clonar el repositorio
git clone https://github.com/DAVID316CORDOVA/MLOps_Taller3.git
cd MLOps_Taller3

# Limpiar entorno previo (si existe)
docker-compose down -v
docker system prune -f
```

### Ejecuci√≥n Completamente Autom√°tica (Recomendado)

```bash
# Despu√©s de la preparaci√≥n inicial, simplemente:
docker-compose up
```

**Qu√© sucede autom√°ticamente:**
- Se crean todos los contenedores necesarios
- Airflow inicia con credenciales admin/admin
- DAG se activa autom√°ticamente
- Pipeline se ejecuta una vez autom√°ticamente despu√©s de 2 minutos
- FastAPI queda disponible con modelo entrenado

### Ejecuci√≥n en Background

```bash
# Para ejecutar en segundo plano
docker-compose up -d

# Ver logs en tiempo real
docker-compose logs -f dag-auto-trigger
```

### Verificaci√≥n Manual del Estado

```bash
# Verificar que Airflow est√© disponible
curl -f http://localhost:8080/health

# Verificar estado de contenedores
docker-compose ps

# Acceder a la interfaz web
# http://localhost:8080 (admin/admin)
```

## Acceso a Servicios

| Servicio | URL | Credenciales | Descripci√≥n |
|----------|-----|--------------|-------------|
| **Airflow Web** | http://localhost:8080 | admin/admin | Dashboard del pipeline |
| **FastAPI Docs** | http://localhost:8000/docs | - | API de predicciones |
| **MySQL** | localhost:3306 | my_app_user/my_app_pass | Base de datos |
| **Flower (opcional)** | http://localhost:5555 | - | Monitor de Celery |

## Ejecuci√≥n del Proyecto

### 1. Levantamiento de la aplicaci√≥n

![Inicio del sistema](./images/compose.jpg)


### 2. Login de Airflow

![Inicio del sistema](./images/login.jpg)


### 3. Ejecuci√≥n Autom√°tica del Pipeline - DAG Auto-Activo

![Inicio del sistema](./images/dag.jpg)

## 4. Visualizaci√≥n todos los tasks de Airflow ejecut√°ndose automaticamente

![Inicio del sistema](./images/orquesta.jpg)


## 5. Visualizaci√≥n del correcto funcionamiento de la interfaz gr√°fica de FASTAPI 

![Inicio del sistema](./images/fastapi.jpg)


## 6. Predicci√≥n usando el modelo generado autom√°ticamente por AirFlow

![Inicio del sistema](./images/fastapi_prediction.jpg)


## Funciones T√©cnicas Implementadas

### funciones.py - L√≥gica del Pipeline

```python
def insert_data():
    """Inserta datos de Palmer Penguins en MySQL"""
    # Carga dataset Palmer Penguins
    # Limpia valores nulos y NaN
    # Inserta registros en tabla MySQL `penguins_raw`

def clean(df):
    """Limpia y transforma los datos"""
    # Elimina registros con valores nulos
    # Aplica One-Hot Encoding para variables categ√≥ricas (island, sex)
    # Convierte columnas booleanas a enteros
    # Transforma species a valores num√©ricos (1=Adelie, 2=Chinstrap, 3=Gentoo)
    # Retorna DataFrame listo para almacenar en `penguins_clean`

def read_data():
    """Lee y procesa datos desde MySQL"""
    # Extrae registros desde tabla `penguins_raw`
    # Aplica limpieza y codificaci√≥n con `clean()`
    # Inserta datos transformados en tabla `penguins_clean`

def train_model():
    """Entrena y guarda un modelo de Regresi√≥n Log√≠stica"""
    # Carga datos desde tabla `penguins_clean`
    # Divide dataset en entrenamiento y prueba
    # Entrena modelo de clasificaci√≥n
    # Eval√∫a desempe√±o con m√©tricas (accuracy, confusion matrix, classification report)
    # Guarda modelo en `/opt/airflow/models/RegresionLogistica.pkl`

def start_fastapi_server():
    """Prepara entorno FastAPI para servir el modelo"""
    # Verifica existencia del modelo entrenado
    # Configura aplicaci√≥n FastAPI ubicada en `/opt/airflow/dags/fastapi_app.py`
    # Genera archivo de estado `fastapi_ready.txt`
    # Sugiere comando de despliegue con uvicorn

```

### queries.py - Consultas SQL

```sql
DROP_PENGUINS_TABLE = """
DROP TABLE IF EXISTS penguins_raw;
"""

DROP_PENGUINS_CLEAN_TABLE = """
DROP TABLE IF EXISTS penguins_clean;            
 """


CREATE_PENGUINS_TABLE_RAW = """ CREATE TABLE penguins_raw (
            species VARCHAR(50) NULL,
            island VARCHAR(50) NULL,
            bill_length_mm DOUBLE NULL,
            bill_depth_mm DOUBLE NULL,
            flipper_length_mm DOUBLE NULL,
            body_mass_g DOUBLE NULL,
            sex VARCHAR(10) NULL,
            year INT NULL
        )
        """

CREATE_PENGUINS_TABLE_CLEAN = """ CREATE TABLE penguins_clean (
    species INT NULL,
    bill_length_mm DOUBLE NULL,
    bill_depth_mm DOUBLE NULL,
    flipper_length_mm DOUBLE NULL,
    body_mass_g DOUBLE NULL,
    year INT NULL,
    island_Biscoe INT NULL,
    island_Dream INT NULL,
    island_Torgersen INT NULL,
    sex_female INT NULL,
    sex_male INT NULL
        );      
        """
"""

```

## Beneficios de la Automatizaci√≥n

| **Antes (Manual)** | **Despu√©s (Automatizado)** |
|--------------------|-----------------------------|
| Login manual requerido | Acceso autom√°tico con admin/admin |
| Activar DAGs manualmente | DAGs activos autom√°ticamente |
| Trigger manual del pipeline | Auto-ejecuci√≥n programada |
| 5-7 pasos manuales | 1 comando: `docker-compose up` |
| Propenso a errores humanos | Proceso consistente y repetible |
| Tiempo: ~10-15 minutos | Tiempo: ~3-5 minutos sin intervenci√≥n |

## Troubleshooting

### Problema: DAG no se ejecuta autom√°ticamente
```bash
# Verificar que el servicio auto-trigger se ejecut√≥
docker-compose logs dag-auto-trigger

# Ejecutar manualmente si es necesario
docker exec -it $(docker-compose ps -q airflow-scheduler) airflow dags trigger orquestador
```

### Problema: Error de permisos
```bash
# Establecer AIRFLOW_UID correcto
echo "AIRFLOW_UID=$(id -u)" > .env
docker-compose down -v
docker-compose up
```

### Problema: MySQL no conecta
```bash
# Verificar que MySQL est√© corriendo
docker-compose ps mysql

# Verificar logs
docker-compose logs mysql
```

### Problema: Puertos ocupados
```bash
# Verificar puertos en uso
netstat -tlnp | grep -E '8080|8000|3306'

# Detener otros servicios si es necesario
docker-compose down
sudo systemctl stop mysql  # Si MySQL local est√° corriendo
```



## ‚ö° Automatizaci√≥n del DAG

Para evitar activar y ejecutar manualmente el DAG desde la interfaz de Airflow, se agreg√≥ un servicio especial en el `docker-compose.yml` llamado **`dag-auto-trigger`**.  

Este servicio:
- Espera 120 segundos para garantizar que Airflow est√© completamente iniciado.
- Despausa autom√°ticamente el DAG **`orquestador`**.
- Lanza su primera ejecuci√≥n sin intervenci√≥n manual.

| **Antes (Manual)** | **Despu√©s (Automatizado)** |
|--------------------|-----------------------------|
| Activar DAG en la UI | DAG activo autom√°ticamente |
| Trigger manual | Auto-trigger inicial |
| 3‚Äì4 pasos manuales | 1 comando: `docker-compose up` |
| Riesgo de olvidos | Proceso 100% confiable |

---

## üîó Conexiones Configuradas en Airflow

En el archivo `docker-compose.yml` se declararon conexiones globales en las variables de entorno de Airflow. Esto simplifica el uso de **hooks** y **operadores** dentro de los DAGs:

### Conexi√≥n a MySQL
`AIRFLOW_CONN_MYSQL_CONN = 'mysql://my_app_user:my_app_pass@mysql:3306/my_app_db'`  

- Permite que `MySqlHook` y `MySqlOperator` se conecten directamente a la base de datos.  
- Evita hardcodear credenciales dentro de los DAGs.  

### Conexi√≥n para FileSensor
`AIRFLOW_CONN_FS_DEFAULT = 'fs:///'`  

- Usada por `FileSensor` para monitorear archivos en el sistema.  
- √ötil en pipelines basados en llegada de archivos (CSV, parquet, etc.).  

---

## üöÄ Beneficios

- DAG siempre inicia activo y ejecutado en la primera corrida.  
- Configuraci√≥n de conexiones centralizada y reutilizable.  
- Menor riesgo de errores manuales en producci√≥n.  
- Todo listo con **un solo comando**:  










## Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠a | Prop√≥sito |
|-----------|------------|-----------|
| **Orquestaci√≥n** | Apache Airflow 2.6.0 | Pipeline automation |
| **Contenerizaci√≥n** | Docker + Docker Compose | Service orchestration |
| **Base de Datos** | MySQL 8.0 | Data persistence |
| **Cache/Queue** | Redis + PostgreSQL | Airflow backend |
| **API Framework** | FastAPI + Uvicorn | Model serving |
| **ML Libraries** | scikit-learn, pandas | Model training |
| **Task Queue** | Celery | Distributed task execution |

## Logs y Monitoreo

### Ubicaci√≥n de Logs:
- **Airflow Logs:** `./logs/`
- **FastAPI Logs:** `./dags/fastapi.log`
- **Container Logs:** `docker-compose logs [service-name]`

### Comandos de Monitoreo:
```bash
# Ver logs en tiempo real de todos los servicios
docker-compose logs -f

# Ver logs espec√≠ficos de un servicio
docker-compose logs airflow-scheduler
docker-compose logs fastapi
docker-compose logs mysql
docker-compose logs dag-auto-trigger

# Verificar estado de contenedores
docker-compose ps

# Ver uso de recursos
docker stats
```

## Conclusiones

Este proyecto demuestra una implementaci√≥n exitosa de MLOps con automatizaci√≥n completa:

1. **Pipeline End-to-End:** Desde datos raw hasta modelo productivo
2. **Zero-Touch Deployment:** Una ejecuci√≥n automatiza todo el proceso
3. **Escalabilidad:** Arquitectura preparada para m√∫ltiples modelos
4. **Monitoreo:** Dashboard web para seguimiento en tiempo real
5. **Reproducibilidad:** Proceso completamente documentado y repetible

La automatizaci√≥n elimina errores humanos y reduce significativamente el tiempo de despliegue, estableciendo una base s√≥lida para operaciones de Machine Learning en producci√≥n.

---

**Desarrollado por:**
- Sebastian Rodr√≠guez
- David C√≥rdova

**Proyecto:** MLOps Taller 3 - Pipeline Automatizado  
**Fecha:** Septiembre 2025
